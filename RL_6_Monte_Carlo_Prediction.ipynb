{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSfGS/TJs7MDNa47yZvlzK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# R054 - Archisha Sinha\n",
        "# MBA Tech AI"
      ],
      "metadata": {
        "id": "v_Zmf1QfqisW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Domain: Reinforcement Learning\n",
        "## Topic: Monte Carlo Prediction - First Visit and Every Visit Algorithm\n",
        "\n"
      ],
      "metadata": {
        "id": "4UERYvGuquVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "J1xlN1oySQg7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "rows, cols = 4, 5\n",
        "states = rows * cols\n",
        "actions = ['left', 'right', 'up', 'down']\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "oN1kpiWUUNUm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize reward matrix (s1 has +50 reward, others random -5 to +5)\n",
        "reward_matrix = np.random.randint(-5, 6, size=(rows, cols))\n",
        "reward_matrix[0][0] = 50  # s1 = 50"
      ],
      "metadata": {
        "id": "BdvaNGl6UPH9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random policy: for each state, pick a random action\n",
        "policy_matrix = np.random.choice(actions, size=(rows, cols))"
      ],
      "metadata": {
        "id": "4KY58VsYUSEA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment display\n",
        "def print_matrix(matrix, title):\n",
        "    print(f\"\\n{title}:\")\n",
        "    for row in matrix:\n",
        "        print(row)"
      ],
      "metadata": {
        "id": "fJX5ASRMUXDX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Action effects (left, right, up, down) as deltas\n",
        "action_effects = {\n",
        "    'left': (0, -1),\n",
        "    'right': (0, 1),\n",
        "    'up': (-1, 0),\n",
        "    'down': (1, 0)\n",
        "}"
      ],
      "metadata": {
        "id": "NIO1QSv3UZRi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random episodes (3 episodes)\n",
        "def generate_episode():\n",
        "    episode = []\n",
        "    current_state = (random.randint(0, rows-1), random.randint(0, cols-1))  # Random start\n",
        "    while len(episode) < 10:  # Arbitrarily keeping episode length to 10 steps max\n",
        "        action = policy_matrix[current_state[0]][current_state[1]]\n",
        "        reward = reward_matrix[current_state[0]][current_state[1]]\n",
        "        episode.append((current_state, action, reward))\n",
        "\n",
        "        delta = action_effects[action]\n",
        "        next_state = (current_state[0] + delta[0], current_state[1] + delta[1])\n",
        "\n",
        "        # Ensure we don't go out of bounds\n",
        "        if 0 <= next_state[0] < rows and 0 <= next_state[1] < cols:\n",
        "            current_state = next_state\n",
        "        else:\n",
        "            break\n",
        "    return episode"
      ],
      "metadata": {
        "id": "am0pEFQ0Udg2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate 3 episodes common for both methods\n",
        "episodes = [generate_episode() for _ in range(3)]"
      ],
      "metadata": {
        "id": "bauebFEAUfrG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJIe5c1fU8m5",
        "outputId": "c84b8b01-3721-4183-ece0-43ff45c1abb4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[((0, 0), 'left', 50)],\n",
              " [((2, 1), 'down', 3),\n",
              "  ((3, 1), 'up', -2),\n",
              "  ((2, 1), 'down', 3),\n",
              "  ((3, 1), 'up', -2),\n",
              "  ((2, 1), 'down', 3),\n",
              "  ((3, 1), 'up', -2),\n",
              "  ((2, 1), 'down', 3),\n",
              "  ((3, 1), 'up', -2),\n",
              "  ((2, 1), 'down', 3),\n",
              "  ((3, 1), 'up', -2)],\n",
              " [((1, 1), 'down', -3),\n",
              "  ((2, 1), 'down', 3),\n",
              "  ((3, 1), 'up', -2),\n",
              "  ((2, 1), 'down', 3),\n",
              "  ((3, 1), 'up', -2),\n",
              "  ((2, 1), 'down', 3),\n",
              "  ((3, 1), 'up', -2),\n",
              "  ((2, 1), 'down', 3),\n",
              "  ((3, 1), 'up', -2),\n",
              "  ((2, 1), 'down', 3)]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize value function for each state\n",
        "value_first_visit = np.zeros((rows, cols))\n",
        "value_every_visit = np.zeros((rows, cols))"
      ],
      "metadata": {
        "id": "Co8JoH6aUhoC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Visit Algorithm"
      ],
      "metadata": {
        "id": "aL5XhoscUoB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First-Visit Monte Carlo Prediction\n",
        "returns_first_visit = {s: [] for s in [(i, j) for i in range(rows) for j in range(cols)]}\n",
        "\n",
        "for episode in episodes:\n",
        "    visited = set()\n",
        "    G = 0\n",
        "    for (state, action, reward) in reversed(episode):\n",
        "        G += reward\n",
        "        if state not in visited:\n",
        "            returns_first_visit[state].append(G)\n",
        "            value_first_visit[state] = np.mean(returns_first_visit[state])\n",
        "            visited.add(state)"
      ],
      "metadata": {
        "id": "TTVFLmpVUmC0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Every Visit Algorithm"
      ],
      "metadata": {
        "id": "rO4Z4-yAUtr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Every-Visit Monte Carlo Prediction\n",
        "returns_every_visit = {s: [] for s in [(i, j) for i in range(rows) for j in range(cols)]}\n",
        "\n",
        "for episode in episodes:\n",
        "    G = 0\n",
        "    for (state, action, reward) in reversed(episode):\n",
        "        G += reward\n",
        "        returns_every_visit[state].append(G)\n",
        "        value_every_visit[state] = np.mean(returns_every_visit[state])"
      ],
      "metadata": {
        "id": "Jks7zT5vUsiK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output results\n",
        "print_matrix(reward_matrix, \"Reward Matrix\")\n",
        "print_matrix(policy_matrix, \"Policy Matrix\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pe3YFLqUxx5",
        "outputId": "0018b377-89f2-4578-caed-c7a7f072d6b4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reward Matrix:\n",
            "[50  4 -4  0 -4]\n",
            "[-3 -3  1 -5  4]\n",
            "[3 3 4 5 4]\n",
            "[-2 -2  2  5  4]\n",
            "\n",
            "Policy Matrix:\n",
            "['left' 'left' 'down' 'left' 'left']\n",
            "['right' 'down' 'left' 'right' 'down']\n",
            "['right' 'down' 'down' 'right' 'down']\n",
            "['down' 'up' 'down' 'left' 'left']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nGenerated Episodes:\")\n",
        "for i, episode in enumerate(episodes):\n",
        "    print(f\"Episode {i+1}: {episode}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP0SKlgbU0ec",
        "outputId": "95089fb8-3249-44e6-bba6-cafd053e7fac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Episodes:\n",
            "Episode 1: [((0, 0), 'left', 50)]\n",
            "Episode 2: [((2, 1), 'down', 3), ((3, 1), 'up', -2), ((2, 1), 'down', 3), ((3, 1), 'up', -2), ((2, 1), 'down', 3), ((3, 1), 'up', -2), ((2, 1), 'down', 3), ((3, 1), 'up', -2), ((2, 1), 'down', 3), ((3, 1), 'up', -2)]\n",
            "Episode 3: [((1, 1), 'down', -3), ((2, 1), 'down', 3), ((3, 1), 'up', -2), ((2, 1), 'down', 3), ((3, 1), 'up', -2), ((2, 1), 'down', 3), ((3, 1), 'up', -2), ((2, 1), 'down', 3), ((3, 1), 'up', -2), ((2, 1), 'down', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_matrix(value_first_visit, \"Value Function (First-Visit MC)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90rx02WfVGTk",
        "outputId": "2bbf0699-c4e1-4cd3-df89-a429f1b52a23"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Value Function (First-Visit MC):\n",
            "[50.  0.  0.  0.  0.]\n",
            "[0. 4. 0. 0. 0.]\n",
            "[0. 2. 0. 0. 0.]\n",
            "[ 0.  -0.5  0.   0.   0. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_matrix(value_every_visit, \"Value Function (Every-Visit MC)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeCjAj-eVJ_5",
        "outputId": "489fbcf0-8aa7-4117-b978-8e77a9ce6aeb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Value Function (Every-Visit MC):\n",
            "[50.  0.  0.  0.  0.]\n",
            "[0. 4. 0. 0. 0.]\n",
            "[0. 4. 0. 0. 0.]\n",
            "[0.         1.11111111 0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "**First-Visit MC Conclusion:**\n",
        "\n",
        "First-Visit MC converges faster due to processing each state only once per episode, resulting in slightly fewer updates. The values obtained are similar to Every-Visit, but computation is more efficient.\n",
        "\n",
        "**Every-Visit MC Conclusion:**\n",
        "\n",
        "Every-Visit MC has higher time complexity as it updates the value function every time a state is visited, leading to more granular value updates. The values are nearly identical, but the method is slower due to repeated updates."
      ],
      "metadata": {
        "id": "9GrmSrW3Vn3U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cxomz_fAVMAl"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}